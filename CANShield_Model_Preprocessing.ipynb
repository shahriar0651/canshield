{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MAC OS\n"
     ]
    }
   ],
   "source": [
    "# Importing PlaidML. Make sure you follow this \n",
    "import os\n",
    "try:\n",
    "    import plaidml.keras\n",
    "    plaidml.keras.install_backend()\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "    from keras import backend as K\n",
    "    # example of training a gan on mnist\n",
    "    import keras\n",
    "    from keras.optimizers import Adam\n",
    "    from keras import Sequential\n",
    "    from keras import layers\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Reshape\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Conv2D\n",
    "    from keras.layers import Conv2DTranspose, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D\n",
    "    from keras.layers import LeakyReLU\n",
    "    from keras.layers import Dropout\n",
    "    from keras.models import load_model\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    #------------------------------\n",
    "    print(\"Running on MAC OS\")\n",
    "except:\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from tensorflow.keras.layers import Reshape\n",
    "    from tensorflow.keras.layers import Flatten\n",
    "    from tensorflow.keras.layers import Conv2D\n",
    "    from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D\n",
    "    from tensorflow.keras.layers import LeakyReLU\n",
    "    from tensorflow.keras.layers import Dropout\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    print(\"Running on Server/PC\")\n",
    "    #------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import exists as file_exists    \n",
    "\n",
    "# Libraries\n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import joblib\n",
    "#------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# import visualkeras\n",
    "\n",
    "# Metric\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "#------------------------------\n",
    "\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "#--------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- Create Folders -------------\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory created!\\n{directory}\")\n",
    "def find_r_from_z (data):\n",
    "    return np.tanh(data)\n",
    "\n",
    "def find_z_from_r (data):\n",
    "    return np.arctanh(data)\n",
    "\n",
    "def rename_sigids(dataframe):\n",
    "    new_list = {}\n",
    "    try:\n",
    "        list_of_sigs = list(dataframe.columns)\n",
    "        dtype = 'df'\n",
    "    except:\n",
    "        list_of_sigs = list(dataframe).copy()\n",
    "        dtype = 'list'\n",
    "        \n",
    "    for sig in list_of_sigs:\n",
    "        sigs = sig.split(\"_\")\n",
    "        if len(sigs) != 5:\n",
    "            new_list[sig] = sig\n",
    "        else:  \n",
    "            sig_no = sigs[1]\n",
    "            id_no = sigs[-1]\n",
    "            if dataset == 'syncan':\n",
    "                new_list[sig] = f\"S:{sig_no.zfill(1)}_ID:{id_no.zfill(2)}\"\n",
    "            else:\n",
    "                new_list[sig] = f\"S:{sig_no.zfill(1)}_ID:{id_no.zfill(4)}\"\n",
    "\n",
    "            \n",
    "    if dtype == 'list':\n",
    "        return list(new_list.values())\n",
    "    else:\n",
    "        dataframe = dataframe.rename(columns=new_list)\n",
    "        dataframe = dataframe.rename(index=new_list)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient files are:\n",
      " ['train_3', 'train_4', 'train_1', 'train_2'], etc.\n",
      "\n",
      "\n",
      "Attack files are:\n",
      " ['test_plateau', 'test_suppress', 'test_continuous', 'test_flooding', 'test_playback'], etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Creating two lists of ambient and attack datasets\n",
    "cur_dir= os.getcwd()\n",
    "dataset = 'syncan'\n",
    "# dataset = 'road'\n",
    "\n",
    "\n",
    "ambient_dirs = glob.glob(cur_dir+f\"//..//data//{dataset}//generated//ambients//*.csv\")\n",
    "attack_dirs = glob.glob(cur_dir+f\"//..//data//{dataset}//generated//attacks//*.csv\")\n",
    "\n",
    "# Creating two lists of file names \n",
    "ambient_files = [x.split(\"/\")[-1].split(\".\")[0][0:-10] for x in ambient_dirs]\n",
    "attack_files = [x.split(\"/\")[-1].split(\".\")[0][0:-10] for x in attack_dirs]\n",
    "\n",
    "print(f\"Ambient files are:\\n {ambient_files[0:]}, etc.\")\n",
    "print(f\"\\n\\nAttack files are:\\n {attack_files[0:]}, etc.\")\n",
    "\n",
    "# %%\n",
    "# ambient_files\n",
    "\n",
    "# %%\n",
    "# Defining parameters..........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_1', 'train_2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambient_files =ambient_files[2:]\n",
    "ambient_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_1\n",
      "Loading dataset:  train_1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1a7d970ab84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         regenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcorr_df_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder_name_data}//Corr_matrix_update_{file_name}.csv\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Saved_Data//Corr_matrix_update_train_1.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1a7d970ab84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Checking if the signalwise data already exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Defining the number of signals..............................\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAFpCAYAAACrn+1KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcYklEQVR4nO3dX4ic53n+8e/1k2JInDQ28SakkkzVosRWi12cjWtC/zgNbSTnQAR8YDvU1ASEwQ45tCn8koJPmoNCCLYjhBEiJ9FJTKoUJaa0JC44brQC/5ONzVam9kYBy3FIwYEa2XcPZtpONivPO7PvszMafT+wsO87j3buh9VcXPvu7EyqCkmSJLXx/2Y9gCRJ0iKzbEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDY8tWkiNJXkvy3AVuT5JvJFlN8kySG/ofU5KmY4ZJmrUuV7aOAvve5fb9wJ7hx0Hgm5sfS5J6cxQzTNIMjS1bVfU48Ma7LDkAfKsGngSuSPLRvgaUpM0wwyTNWh/P2doBvDpyvDY8J0kXAzNMUlPbe/ga2eDchu8BlOQgg8v0XH755Z+45pprerh7SReLU6dOvV5VS7OeYx0zTNJYm8mvPsrWGrBr5HgncHajhVV1GDgMsLy8XCsrKz3cvaSLRZL/mPUMGzDDJI21mfzq49eIx4E7h3/RcxPwy6r6WQ9fV5K2ghkmqamxV7aSfBu4GbgqyRrwVeA9AFV1CDgB3AKsAr8C7mo1rCRNygyTNGtjy1ZV3T7m9gLu6W0iSeqRGSZp1nwFeUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJaqhT2UqyL8mLSVaT3L/B7R9M8r0kTyc5neSu/keVpMmZX5JmbWzZSrINeAjYD+wFbk+yd92ye4Dnq+p64Gbg75Nc1vOskjQR80vSPOhyZetGYLWqzlTVW8Ax4MC6NQV8IEmA9wNvAOd7nVSSJmd+SZq5LmVrB/DqyPHa8NyoB4FrgbPAs8CXq+qd9V8oycEkK0lWzp07N+XIktRZb/kFZpik6XQpW9ngXK07/izwFPDbwB8CDyb5rd/4R1WHq2q5qpaXlpYmHFWSJtZbfoEZJmk6XcrWGrBr5Hgng58AR90FPFoDq8DLwDX9jChJUzO/JM1cl7J1EtiTZPfwSaO3AcfXrXkF+AxAko8AHwfO9DmoJE3B/JI0c9vHLaiq80nuBR4DtgFHqup0kruHtx8CHgCOJnmWwWX7+6rq9YZzS9JY5pekeTC2bAFU1QngxLpzh0Y+Pwv8Zb+jSdLmmV+SZs1XkJckSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIY6la0k+5K8mGQ1yf0XWHNzkqeSnE7yo37HlKTpmF+SZm37uAVJtgEPAX8BrAEnkxyvqudH1lwBPAzsq6pXkny40byS1Jn5JWkedLmydSOwWlVnquot4BhwYN2aO4BHq+oVgKp6rd8xJWkq5pekmetStnYAr44crw3PjfoYcGWSHyY5leTOjb5QkoNJVpKsnDt3brqJJam73vILzDBJ0+lStrLBuVp3vB34BPA54LPA/0/ysd/4R1WHq2q5qpaXlpYmHlaSJtRbfoEZJmk6Y5+zxeAnwV0jxzuBsxuseb2q3gTeTPI4cD3wUi9TStJ0zC9JM9flytZJYE+S3UkuA24Djq9b8w/AnyTZnuR9wB8BL/Q7qiRNzPySNHNjr2xV1fkk9wKPAduAI1V1Osndw9sPVdULSX4APAO8AzxSVc+1HFySxjG/JM2DVK1/+sLWWF5erpWVlZnct6TZSHKqqpZnPUcfzDDp0rKZ/PIV5CVJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1FCnspVkX5IXk6wmuf9d1n0yydtJbu1vREmanvkladbGlq0k24CHgP3AXuD2JHsvsO5rwGN9DylJ0zC/JM2DLle2bgRWq+pMVb0FHAMObLDuS8B3gNd6nE+SNsP8kjRzXcrWDuDVkeO14bn/lWQH8HngUH+jSdKmmV+SZq5L2coG52rd8deB+6rq7Xf9QsnBJCtJVs6dO9dxREmaWm/5BWaYpOls77BmDdg1crwTOLtuzTJwLAnAVcAtSc5X1XdHF1XVYeAwwPLy8vrAk6S+9ZZfYIZJmk6XsnUS2JNkN/BT4DbgjtEFVbX7fz5PchT4x42CSpK2mPklaebGlq2qOp/kXgZ/pbMNOFJVp5PcPbzd5zlImkvml6R50OXKFlV1Ajix7tyGIVVVf735sSSpH+aXpFnzFeQlSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKmhTmUryb4kLyZZTXL/Brd/Ickzw48nklzf/6iSNDnzS9KsjS1bSbYBDwH7gb3A7Un2rlv2MvBnVXUd8ABwuO9BJWlS5pekedDlytaNwGpVnamqt4BjwIHRBVX1RFX9Ynj4JLCz3zElaSrml6SZ61K2dgCvjhyvDc9dyBeB7290Q5KDSVaSrJw7d677lJI0nd7yC8wwSdPpUraywbnacGHyaQZhdd9Gt1fV4aparqrlpaWl7lNK0nR6yy8wwyRNZ3uHNWvArpHjncDZ9YuSXAc8Auyvqp/3M54kbYr5JWnmulzZOgnsSbI7yWXAbcDx0QVJrgYeBf6qql7qf0xJmor5JWnmxl7ZqqrzSe4FHgO2AUeq6nSSu4e3HwK+AnwIeDgJwPmqWm43tiSNZ35Jmgep2vDpC80tLy/XysrKTO5b0mwkObUoRcYMky4tm8kvX0FekiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNdSpbSfYleTHJapL7N7g9Sb4xvP2ZJDf0P6okTc78kjRrY8tWkm3AQ8B+YC9we5K965btB/YMPw4C3+x5TkmamPklaR50ubJ1I7BaVWeq6i3gGHBg3ZoDwLdq4EngiiQf7XlWSZqU+SVp5rqUrR3AqyPHa8Nzk66RpK1mfkmaue0d1mSDczXFGpIcZHCZHuC/kjzX4f4vBlcBr896iJ4syl4WZR+wWHv5+BbfX2/5BQubYYv0/8u9zJ9F2QdsIr+6lK01YNfI8U7g7BRrqKrDwGGAJCtVtTzRtHPKvcyfRdkHLN5etvgue8svWMwMW5R9gHuZR4uyD9hcfnX5NeJJYE+S3UkuA24Djq9bcxy4c/hXPTcBv6yqn007lCT1xPySNHNjr2xV1fkk9wKPAduAI1V1Osndw9sPASeAW4BV4FfAXe1GlqRuzC9J86DLrxGpqhMMAmn03KGRzwu4Z8L7Pjzh+nnmXubPouwD3MumNMovWJzvy6LsA9zLPFqUfcAm9pJBzkiSJKkF365HkiSpoeZla5HeKqPDXr4w3MMzSZ5Icv0s5hxn3D5G1n0yydtJbt3K+SbRZS9Jbk7yVJLTSX601TN21eH/1weTfC/J08O9zOVzi5IcSfLahV4WYcEe84u0l4siv2BxMsz8mj/N8quqmn0weELqvwO/C1wGPA3sXbfmFuD7DF7r5ibg31rO1HgvnwKuHH6+fx730mUfI+v+hcFzXW6d9dyb+J5cATwPXD08/vCs597EXv4G+Nrw8yXgDeCyWc++wV7+FLgBeO4Cty/SY36R9jL3+dV1LyPr5jbDzK9LK79aX9lapLfKGLuXqnqiqn4xPHySwev1zJsu3xOALwHfAV7byuEm1GUvdwCPVtUrAFU1r/vpspcCPpAkwPsZhNX5rR1zvKp6nMFsF7Iwj3kWaC8XSX7B4mSY+XUJ5VfrsrVIb5Ux6ZxfZNB+583YfSTZAXweOMR86/I9+RhwZZIfJjmV5M4tm24yXfbyIHAtgxfcfBb4clW9szXj9WqRHvOLtJdR85pfsDgZZn5dQvnV6aUfNqHXt8qYsUne0uPTDMLqj5tONJ0u+/g6cF9VvT34IWRuddnLduATwGeA9wI/TvJkVb3UergJddnLZ4GngD8Hfg/4pyT/WlX/2Xi2vi3SY36R9jJYON/5BYuTYebXJZRfrctWr2+VMWOd5kxyHfAIsL+qfr5Fs02iyz6WgWPDkLoKuCXJ+ar67pZM2F3X/1+vV9WbwJtJHgeuB+YtrLrs5S7g72rwxIHVJC8D1wA/2ZoRe7NIj/lF2svFkF+wOBlmfl1K+dX4iWbbgTPAbv7vSXO/v27N5/j1J5v9pOVMjfdyNYNXof7UrOfdzD7WrT/KHD65dILvybXAPw/Xvg94DviDWc8+5V6+Cfzt8POPAD8Frpr17BfYz+9w4SeYLtJjfpH2Mvf51XUv69bPZYaZX5dWfjW9slUL9FYZHffyFeBDwMPDn6jO15y9AWfHfVwUuuylql5I8gPgGeAd4JGq2vBPemep4/flAeBokmcZPNDvq6rXZzb0BST5NnAzcFWSNeCrwHtgIR/zi7SXuc8vWJwMM78urfzyFeQlSZIa8hXkJUmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDU0tmwlOZLktSQbvh9TBr6RZDXJM0lu6H9MSZqOGSZp1rpc2ToK7HuX2/cDe4YfBxm8s7ckzYujmGGSZmhs2aqqx4E33mXJAeBbNfAkcEWSj/Y1oCRthhkmadb6eM7WDuDVkeO14TlJuhiYYZKa2t7D18gG52rDhclBBpfpufzyyz9xzTXX9HD3ki4Wp06der2qlmY9xzpmmKSxNpNffZStNWDXyPFO4OxGC6vqMHAYYHl5uVZWVnq4e0kXiyT/MesZNmCGSRprM/nVx68RjwN3Dv+i5ybgl1X1sx6+riRtBTNMUlNjr2wl+TZwM3BVkjXgq8B7AKrqEHACuAVYBX4F3NVqWEmalBkmadbGlq2qun3M7QXc09tEktQjM0zSrPkK8pIkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1FCnspVkX5IXk6wmuX+D2z+Y5HtJnk5yOsld/Y8qSZMzvyTN2tiylWQb8BCwH9gL3J5k77pl9wDPV9X1wM3A3ye5rOdZJWki5pekedDlytaNwGpVnamqt4BjwIF1awr4QJIA7wfeAM73OqkkTc78kjRzXcrWDuDVkeO14blRDwLXAmeBZ4EvV9U7679QkoNJVpKsnDt3bsqRJamz3vILzDBJ0+lStrLBuVp3/FngKeC3gT8EHkzyW7/xj6oOV9VyVS0vLS1NOKokTay3/AIzTNJ0upStNWDXyPFOBj8BjroLeLQGVoGXgWv6GVGSpmZ+SZq5LmXrJLAnye7hk0ZvA46vW/MK8BmAJB8BPg6c6XNQSZqC+SVp5raPW1BV55PcCzwGbAOOVNXpJHcPbz8EPAAcTfIsg8v291XV6w3nlqSxzC9J82Bs2QKoqhPAiXXnDo18fhb4y35Hk6TNM78kzZqvIC9JktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIY6la0k+5K8mGQ1yf0XWHNzkqeSnE7yo37HlKTpmF+SZm37uAVJtgEPAX8BrAEnkxyvqudH1lwBPAzsq6pXkny40byS1Jn5JWkedLmydSOwWlVnquot4BhwYN2aO4BHq+oVgKp6rd8xJWkq5pekmetStnYAr44crw3PjfoYcGWSHyY5leTOvgaUpE0wvyTN3NhfIwLZ4Fxt8HU+AXwGeC/w4yRPVtVLv/aFkoPAQYCrr7568mklaTK95ReYYZKm0+XK1hqwa+R4J3B2gzU/qKo3q+p14HHg+vVfqKoOV9VyVS0vLS1NO7MkddVbfoEZJmk6XcrWSWBPkt1JLgNuA46vW/MPwJ8k2Z7kfcAfAS/0O6okTcz8kjRzY3+NWFXnk9wLPAZsA45U1ekkdw9vP1RVLyT5AfAM8A7wSFU913JwSRrH/JI0D1K1/ukLW2N5eblWVlZmct+SZiPJqapanvUcfTDDpEvLZvLLV5CXJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGOpWtJPuSvJhkNcn977Luk0neTnJrfyNK0vTML0mzNrZsJdkGPATsB/YCtyfZe4F1XwMe63tISZqG+SVpHnS5snUjsFpVZ6rqLeAYcGCDdV8CvgO81uN8krQZ5pekmetStnYAr44crw3P/a8kO4DPA4fe7QslOZhkJcnKuXPnJp1VkibVW34N15phkibWpWxlg3O17vjrwH1V9fa7faGqOlxVy1W1vLS01HFESZpab/kFZpik6WzvsGYN2DVyvBM4u27NMnAsCcBVwC1JzlfVd/sYUpKmZH5JmrkuZesksCfJbuCnwG3AHaMLqmr3/3ye5CjwjwaVpDlgfkmaubFlq6rOJ7mXwV/pbAOOVNXpJHcPbx/7PAdJmgXzS9I86HJli6o6AZxYd27DkKqqv978WJLUD/NL0qz5CvKSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktRQp7KVZF+SF5OsJrl/g9u/kOSZ4ccTSa7vf1RJmpz5JWnWxpatJNuAh4D9wF7g9iR71y17GfizqroOeAA43PegkjQp80vSPOhyZetGYLWqzlTVW8Ax4MDogqp6oqp+MTx8EtjZ75iSNBXzS9LMdSlbO4BXR47Xhucu5IvA9ze6IcnBJCtJVs6dO9d9SkmaTm/5BWaYpOl0KVvZ4FxtuDD5NIOwum+j26vqcFUtV9Xy0tJS9yklaTq95ReYYZKms73DmjVg18jxTuDs+kVJrgMeAfZX1c/7GU+SNsX8kjRzXa5snQT2JNmd5DLgNuD46IIkVwOPAn9VVS/1P6YkTcX8kjRzY69sVdX5JPcCjwHbgCNVdTrJ3cPbDwFfAT4EPJwE4HxVLbcbW5LGM78kzYNUbfj0heaWl5drZWVlJvctaTaSnFqUImOGSZeWzeSXryAvSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGOpWtJPuSvJhkNcn9G9yeJN8Y3v5Mkhv6H1WSJmd+SZq1sWUryTbgIWA/sBe4Pcnedcv2A3uGHweBb/Y8pyRNzPySNA+6XNm6EVitqjNV9RZwDDiwbs0B4Fs18CRwRZKP9jyrJE3K/JI0c13K1g7g1ZHjteG5SddI0lYzvyTN3PYOa7LBuZpiDUkOMrhMD/BfSZ7rcP8Xg6uA12c9RE8WZS+Lsg9YrL18fIvvr7f8goXNsEX6/+Ve5s+i7AM2kV9dytYasGvkeCdwdoo1VNVh4DBAkpWqWp5o2jnlXubPouwDFm8vW3yXveUXLGaGLco+wL3Mo0XZB2wuv7r8GvEksCfJ7iSXAbcBx9etOQ7cOfyrnpuAX1bVz6YdSpJ6Yn5JmrmxV7aq6nySe4HHgG3Akao6neTu4e2HgBPALcAq8CvgrnYjS1I35pekedDl14hU1QkGgTR67tDI5wXcM+F9H55w/TxzL/NnUfYB7mVTGuUXLM73ZVH2Ae5lHi3KPmATe8kgZyRJktSCb9cjSZLUUPOytUhvldFhL18Y7uGZJE8kuX4Wc44zbh8j6z6Z5O0kt27lfJPospckNyd5KsnpJD/a6hm76vD/64NJvpfk6eFe5vK5RUmOJHntQi+LsGCP+UXay0WRX7A4GWZ+zZ9m+VVVzT4YPCH134HfBS4Dngb2rltzC/B9Bq91cxPwby1naryXTwFXDj/fP4976bKPkXX/wuC5LrfOeu5NfE+uAJ4Hrh4ef3jWc29iL38DfG34+RLwBnDZrGffYC9/CtwAPHeB2xfpMb9Ie5n7/Oq6l5F1c5th5tellV+tr2wt0ltljN1LVT1RVb8YHj7J4PV65k2X7wnAl4DvAK9t5XAT6rKXO4BHq+oVgKqa1/102UsBH0gS4P0Mwur81o45XlU9zmC2C1mYxzwLtJeLJL9gcTLM/LqE8qt12Vqkt8qYdM4vMmi/82bsPpLsAD4PHGK+dfmefAy4MskPk5xKcueWTTeZLnt5ELiWwQtuPgt8uare2ZrxerVIj/lF2suoec0vWJwMM78uofzq9NIPm9DrW2XM2CRv6fFpBmH1x00nmk6XfXwduK+q3h78EDK3uuxlO/AJ4DPAe4EfJ3myql5qPdyEuuzls8BTwJ8Dvwf8U5J/rar/bDxb3xbpMb9IexksnO/8gsXJMPPrEsqv1mWr17fKmLFOcya5DngE2F9VP9+i2SbRZR/LwLFhSF0F3JLkfFV9d0sm7K7r/6/Xq+pN4M0kjwPXA/MWVl32chfwdzV44sBqkpeBa4CfbM2IvVmkx/wi7eViyC9YnAwzvy6l/Gr8RLPtwBlgN//3pLnfX7fmc/z6k81+0nKmxnu5msGrUH9q1vNuZh/r1h9lDp9cOsH35Frgn4dr3wc8B/zBrGefci/fBP52+PlHgJ8CV8169gvs53e48BNMF+kxv0h7mfv86rqXdevnMsPMr0srv5pe2aoFequMjnv5CvAh4OHhT1Tna87egLPjPi4KXfZSVS8k+QHwDPAO8EhVbfgnvbPU8fvyAHA0ybMMHuj3VdXrMxv6ApJ8G7gZuCrJGvBV4D2wkI/5RdrL3OcXLE6GmV+XVn75CvKSJEkN+QrykiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIb+GxIDJzSPRLoUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del corr_df_mean, corr_df_max, z_fisher\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# reading each dataset in a df file\n",
    "folder_name_data = \"Saved_Data\"\n",
    "folder_name_plots = \"overall\"\n",
    "\n",
    "ensure_dir(f\"{folder_name_data}//\")\n",
    "ensure_dir(f\"plots//{folder_name_plots}//\")\n",
    "\n",
    "if dataset == 'syncan':\n",
    "    fig, axes = plt.subplots(2, 2, figsize = (10,6))\n",
    "else:\n",
    "    fig, axes = plt.subplots(3, 4, figsize = (16,8))\n",
    "    \n",
    "axs = axes.flatten()\n",
    "df_scale = pd.DataFrame([])\n",
    "\n",
    "for indx, (file_name, file_dir) in enumerate(zip(ambient_files, ambient_dirs)):\n",
    "    ax = axs[indx]\n",
    "#     if file_name !=  'ambient_dyno_drive_basic_short':\n",
    "#         continue\n",
    "        \n",
    "    print(file_name)\n",
    "\n",
    "    try:\n",
    "        #Try loading corr mat.............\n",
    "#         regenerate\n",
    "        corr_df_new = abs(pd.read_csv(f\"{folder_name_data}//Corr_matrix_update_{file_name}.csv\" ,index_col=0).fillna(0))\n",
    "        print(f\"Loaded {file_name}\")\n",
    "        \n",
    "    except:\n",
    "        #Generate corr mat and store......\n",
    "        print(\"Loading dataset: \",file_name)\n",
    "        # Checking if the signalwise data already exists\n",
    "        X_train = pd.read_csv(file_dir, index_col = 0) \n",
    "\n",
    "        # Defining the number of signals..............................\n",
    "        X_train = X_train.copy()\n",
    "        X_train = X_train.drop(columns = ['Label', 'Time', 'ID']).copy()\n",
    "\n",
    "        if dataset == 'road':\n",
    "            # Forward filling algorithm........\n",
    "            print(\"Forward filling...\")\n",
    "            X_train = X_train.ffill().copy()\n",
    "            X_train = X_train.bfill().dropna()   \n",
    "            #--------------------------------\n",
    "            print(\"X_train.shape\", X_train.shape)\n",
    "            #------------------------------------\n",
    "        else:\n",
    "            print(\"No treatment needed for SynCAN!\")\n",
    "        \n",
    "        # Loading data..........................\n",
    "        # X_train = X_train.values\n",
    "        \n",
    "        #Saving scaler data.........................................\n",
    "        scaler_train = MinMaxScaler()\n",
    "        scaler_train.fit(X_train.values)\n",
    "        df_scale[f'{file_name}_max'] = list(scaler_train.data_max_)\n",
    "        df_scale[f'{file_name}_min'] = list(scaler_train.data_min_)\n",
    "        #............................................................\n",
    "\n",
    "        #Correlation matrix..........................................\n",
    "        corr_df_new = X_train[0::100].corr().fillna(0).copy()\n",
    "        #Saving corr mat.......................\n",
    "        corr_df_new.to_csv(f\"{folder_name_data}//Corr_matrix_update_{file_name}.csv\", index = True, header = True)\n",
    "        #Corr mat is loaded...........................................\n",
    "\n",
    "    try:\n",
    "#         print(\" Updating pixels..... 1\")\n",
    "        corr_df_mean += corr_df_new\n",
    "        col_list = corr_df_new.columns.to_list()\n",
    "        indeces = corr_df_new.loc[col_list,col_list] > corr_df_max.loc[col_list,col_list] \n",
    "        corr_df_max[indeces] = corr_df_new[indeces].copy()\n",
    "#         corr_df_max[corr_df_new > corr_df_max] = corr_df_new[corr_df_new > corr_df_max].copy()\n",
    "        z_fisher += find_z_from_r(corr_df_new.values)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Failed to upload to ftp: '+ str(e))\n",
    "        print(\"*********** Adding new Corr *************\")\n",
    "        columns_list = corr_df_new.columns.tolist()\n",
    "        corr_df_mean = corr_df_new.copy()\n",
    "        corr_df_max = corr_df_new.copy()\n",
    "        z_fisher = find_z_from_r(corr_df_new.values)\n",
    "        \n",
    "    ax = sns.heatmap(corr_df_new, ax = ax, xticklabels=False, yticklabels=False)\n",
    "    ax.set_title(file_name)\n",
    "#     ax.tick_params(left=False, bottom=False) ## other options are right and top\n",
    "fig.suptitle(\"Correlation heatmaps of different files\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots//{folder_name_plots}//Corr_Heatmaps_{dataset}.jpg\", dpi = 350) \n",
    "plt.show()\n",
    "\n",
    "# Finalizing the corr mats.......................\n",
    "corr_df_mean = (corr_df_mean/len(ambient_files)).fillna(0)\n",
    "z_fisher = z_fisher/len(ambient_files)\n",
    "corr_df_fisher = pd.DataFrame(find_r_from_z(z_fisher)).fillna(0)\n",
    "corr_df_fisher.columns = corr_df_mean.columns\n",
    "corr_df_fisher.index = corr_df_mean.index\n",
    "\n",
    "try:\n",
    "    df_scale.index = X_train.columns\n",
    "    df_scale = df_scale.T.copy()\n",
    "    df_scale.to_csv(f\"Scalling_Data/min_max_values_{dataset}.csv\", header=True, index=True)\n",
    "    #.................................................\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Saved_Data//Corr_matrix_update_train_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c3ef5eefcf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr_df_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder_name_data}//Corr_matrix_update_{file_name}.csv\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Saved_Data//Corr_matrix_update_train_1.csv'"
     ]
    }
   ],
   "source": [
    "corr_df_new = abs(pd.read_csv(f\"{folder_name_data}//Corr_matrix_update_{file_name}.csv\" ,index_col=0).fillna(0))\n",
    "print(f\"Loaded {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(4,5, figsize = (12, 4.5), sharex = True)\n",
    "# for sig, ax in zip(top_signals, axes.flatten()):\n",
    "#     X_train[sig][0:1000000].plot(ax = ax, marker = 'p', linestyle = '--', markersize= '0.5')\n",
    "#     ax.set_title(sig)\n",
    "#     ax.set_xlabel(\"Time Step\")\n",
    "# fig.suptitle(\"Time series plot of different signals\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f\"plots//{folder_name_plots}//Time_series_{dataset}.jpg\", dpi = 350) \n",
    "# plt.savefig(f\"plots//{folder_name_plots}//Time_series_{dataset}.pdf\") \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.heatmap(corr_df_mean, vmin = 0, vmax = 1 )\n",
    "# fig.suptitle(\"Correlation heatmaps of different files\")\n",
    "plt.title(\"Overall correltion heatmap: Mean\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots//{folder_name_plots}//Corr_Heatmap_Overall_{dataset}_Mean.jpg\", dpi = 350) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.heatmap(corr_df_fisher, vmin = 0, vmax = 1 )\n",
    "# fig.suptitle(\"Correlation heatmaps of different files\")\n",
    "plt.title(\"Overall correltion heatmap: Z Fischer\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots//{folder_name_plots}//Corr_Heatmap_Overall_{dataset}_Fischer.jpg\", dpi = 350) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_Signals = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'syncan':\n",
    "    top_signals = list(corr_df_fisher.columns)\n",
    "else:\n",
    "    # Opening attacked signals file\n",
    "    #-----------------------\n",
    "    f = open(cur_dir+f\"//Saved_Data//attacked_signals.json\")\n",
    "    attacked_signals = json.load(f)\n",
    "    f.close()\n",
    "    x = [] \n",
    "    for val in attacked_signals.values(): x +=val\n",
    "    targeted_signals = list(set(x))\n",
    "\n",
    "    # Top 20 signals........................\n",
    "    top_signals_df = pd.DataFrame([])\n",
    "\n",
    "    for targeted_signal in targeted_signals:\n",
    "        top_signals_df[targeted_signal] = corr_df_fisher[targeted_signal].sort_values(ascending=False).index\n",
    "\n",
    "    # ......................\n",
    "    top_signals = targeted_signals.copy()\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    while(len(top_signals) < num_of_Signals):\n",
    "\n",
    "        sig = top_signals_df.iloc[row, col]\n",
    "        #print(f\"{row}, {col} : {sig}\")\n",
    "        if sig not in top_signals:\n",
    "            top_signals.append(sig)\n",
    "    #         print(f\"Adding {sig}\")\n",
    "        col += 1  \n",
    "\n",
    "        if col == len(targeted_signals):\n",
    "            #print(\"going to the next row...\")\n",
    "            col = 0\n",
    "            row += 1      \n",
    "    #     print(len(top_signals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize = (17, 5))\n",
    "\n",
    "#------------ Clustering again ---------------\n",
    "# Plotting the correlation matrix...........\n",
    "\n",
    "# corr_df_target = corr_df_fisher.copy()\n",
    "\n",
    "corr_df_target = corr_df_mean.copy()\n",
    "\n",
    "\n",
    "top_signals = rename_sigids(top_signals)\n",
    "corr_df_target = rename_sigids(corr_df_target)\n",
    "\n",
    "corr_df = abs(corr_df_target.loc[top_signals,top_signals]).copy()\n",
    "\n",
    "\n",
    "sns.heatmap(corr_df, ax = axes[0]) # unclustered version\n",
    "# plt.savefig(f\"plots/heatmap_before_{file_name}.jpg\", dpi = 500)\n",
    "# plt.show()\n",
    "axes[0].set_title(\"Correlation before clustering\")\n",
    "\n",
    "#--------------------------------------------\n",
    "corr_array = corr_df.copy()\n",
    "inplace = False\n",
    "pairwise_distances = sch.distance.pdist(corr_array)\n",
    "linkage = sch.linkage(pairwise_distances, method='complete')\n",
    "\n",
    "#--------------------------------------------\n",
    "# plt.figure(figsize=(5, 5)) \n",
    "axes[1].set_title(\"Dendrograms of hierarchical clustering\")\n",
    "dend = sch.dendrogram(linkage, orientation='right', labels=corr_df.index, ax =axes[1])\n",
    "#--------------------------------------------\n",
    "# Plotting the correlation matrix...........\n",
    "sns.heatmap(corr_df.loc[dend['ivl'][::-1], dend['ivl'][::-1]], ax = axes[2])\n",
    "axes[2].set_title(\"Correlation after clustering\")\n",
    "\n",
    "if dataset == 'syncan':\n",
    "    fig.suptitle(f\"Signal clustering and rearranging based on correlations: SynCAN dataset\")\n",
    "else:\n",
    "    fig.suptitle(f\"Signal clustering and rearranging based on correlations: ROAD dataset\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots//{folder_name_plots}//heatmap_before_after_den_{dataset}.jpg\", dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "#Updating the columns sequence\n",
    "#--------------------------------------------\n",
    "# print(dend['ivl'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Top 50\n",
    "\n",
    "# list_of_sigs = dend['ivl'][::-1]\n",
    "# list_of_sigs\n",
    "# ['S:4_ID:0167',\n",
    "#  'S:2_ID:1505',\n",
    "#  'S:4_ID:1031',\n",
    "#  'S:1_ID:0051',\n",
    "#  'S:4_ID:0778',\n",
    "#  'S:8_ID:0778',\n",
    "#  'S:4_ID:1628',\n",
    "#  'S:2_ID:1255',\n",
    "#  'S:2_ID:0526',\n",
    "#  'S:1_ID:1760',\n",
    "#  'S:4_ID:1176',\n",
    "#  'S:6_ID:0208',\n",
    "#  'S:3_ID:1760',\n",
    "#  'S:4_ID:1760',\n",
    "#  'S:2_ID:1760',\n",
    "#  'S:1_ID:0167',\n",
    "#  'S:7_ID:0208',\n",
    "#  'S:5_ID:1590',\n",
    "#  'S:7_ID:1628',\n",
    "#  'S:9_ID:1413',\n",
    "#  'S:9_ID:0167',\n",
    "#  'S:8_ID:1455',\n",
    "#  'S:5_ID:0640',\n",
    "#  'S:2_ID:0852',\n",
    "#  'S:3_ID:0622',\n",
    "#  'S:2_ID:1398',\n",
    "#  'S:9_ID:1455',\n",
    "#  'S:3_ID:1076',\n",
    "#  'S:11_ID:1031',\n",
    "#  'S:10_ID:0470',\n",
    "#  'S:1_ID:0683',\n",
    "#  'S:2_ID:0778',\n",
    "#  'S:6_ID:0628',\n",
    "#  'S:6_ID:0167',\n",
    "#  'S:3_ID:0208',\n",
    "#  'S:1_ID:0852',\n",
    "#  'S:7_ID:1788',\n",
    "#  'S:2_ID:0051',\n",
    "#  'S:7_ID:0354',\n",
    "#  'S:3_ID:0996',\n",
    "#  'S:1_ID:1634',\n",
    "#  'S:2_ID:0208',\n",
    "#  'S:1_ID:0014',\n",
    "#  'S:3_ID:0014',\n",
    "#  'S:8_ID:0470',\n",
    "#  'S:2_ID:0061',\n",
    "#  'S:2_ID:0204',\n",
    "#  'S:3_ID:0458',\n",
    "#  'S:5_ID:1372',\n",
    "#  'S:5_ID:0631']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "\n",
    "# list_of_sigs = dend['ivl'][::-1]\n",
    "# list_of_sigs\n",
    "# ['S:4_ID:1628',\n",
    "#  'S:2_ID:1255',\n",
    "#  'S:3_ID:1760',\n",
    "#  'S:6_ID:0208',\n",
    "#  'S:1_ID:1760',\n",
    "#  'S:4_ID:1760',\n",
    "#  'S:2_ID:1760',\n",
    "#  'S:5_ID:1590',\n",
    "#  'S:3_ID:0208',\n",
    "#  'S:3_ID:0014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Top 5\n",
    "# # list_of_sigs = dend['ivl'][::-1]\n",
    "# # list_of_sigs\n",
    "# ['S:3_ID:1760',\n",
    "#  'S:6_ID:0208',\n",
    "#  'S:1_ID:1760',\n",
    "#  'S:4_ID:1760',\n",
    "#  'S:2_ID:1760',\n",
    "#  'S:2_ID:1255',\n",
    "#  'S:3_ID:0208']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
