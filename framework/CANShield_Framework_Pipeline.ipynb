{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries.......\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collective-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading parameters and dataset\n",
    "platform = \"PC\"\n",
    "# platform = 'RPi'\n",
    "if platform != \"PC\":\n",
    "\n",
    "    # import Interpreter\n",
    "    # from tflite_runtime.interpreter import Interpreter\n",
    "\n",
    "    \n",
    "    #import libraries for led blinking\n",
    "    from gpiozero import LED\n",
    "\n",
    "    # Defining three LEDs\n",
    "    dataLED = LED(23)\n",
    "    attackLED = LED(24)\n",
    "    detectionLED = LED(25)\n",
    "# else:\n",
    "#     # from tf.lite import Interpreter\n",
    "#     import tensorflow.lite.Interpreter as Interpreter\n",
    "\n",
    "\n",
    "# Defining IDs and number of associated signals\n",
    "list_of_ids = list(range(1, 11))\n",
    "num_of_id = [2, 3, 2, 1, 2, 2, 2, 1, 1, 4]\n",
    "num_sigs_per_id = {}\n",
    "for can_id, n_id in zip(list_of_ids, num_of_id):\n",
    "    num_sigs_per_id[can_id] = n_id\n",
    "\n",
    "\n",
    "# #Loading Raw Data Frame\n",
    "folder_dir = 'data/syncan_cut/'\n",
    "target_file = \"test_flooding\"\n",
    "data_dir = folder_dir+target_file+'_cut.csv'\n",
    "\n",
    "with open(data_dir,'r') as dest_f:\n",
    "    data_iter = csv.reader(dest_f,\n",
    "                           delimiter = ',',\n",
    "                           quotechar = '\"')\n",
    "    data = [data for data in data_iter]\n",
    "df_raw = pd.DataFrame(data)\n",
    "df_raw.columns = ['Label', 'Time', 'ID','Signal1', 'Signal2', 'Signal3', 'Signal4']\n",
    "df_raw = df_raw.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34857a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acknowledged-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected signals...\n",
    "signals_in_cluster = ['Sig_2_of_ID_7',\n",
    " 'Sig_2_of_ID_1',\n",
    " 'Sig_1_of_ID_3',\n",
    " 'Sig_2_of_ID_10',\n",
    " 'Sig_2_of_ID_6',\n",
    " 'Sig_1_of_ID_8',\n",
    " 'Sig_3_of_ID_2',\n",
    " 'Sig_1_of_ID_5',\n",
    " 'Sig_1_of_ID_4',\n",
    " 'Sig_1_of_ID_6',\n",
    " 'Sig_2_of_ID_5',\n",
    " 'Sig_3_of_ID_10',\n",
    " 'Sig_2_of_ID_3',\n",
    " 'Sig_1_of_ID_2',\n",
    " 'Sig_1_of_ID_7',\n",
    " 'Sig_2_of_ID_2',\n",
    " 'Sig_1_of_ID_1',\n",
    " 'Sig_4_of_ID_10',\n",
    " 'Sig_1_of_ID_10',\n",
    " 'Sig_1_of_ID_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "awful-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "apart-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'syncan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc27b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting saved model to a TensorFlow Lite model.\n",
    "for w in [20, 50, 100]:\n",
    "    T_x = 1\n",
    "    filename = f'models/lite_models//Autoencoder_Final_{w}_1_{T_x}_True'\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(filename)\n",
    "    tflite_model = converter.convert()\n",
    "    open(f'models/tflite_models//Autoencoder_Final_{w}_1_{T_x}_True.tflite' , \"wb\") .write(tflite_model)\n",
    "    # Set interpreter...\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "# print(interpreters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf64b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"models/tflite_models_quant/\")\n",
    "# tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Converting saved model to a TensorFlow Lite model.\n",
    "for w in [20, 50, 100]:\n",
    "    T_x = 1\n",
    "    filename = f'models/original_models//Autoencoder_Final_{w}_1_{T_x}_True.h5'\n",
    "    autoencoder = load_model(filename)\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "\n",
    "    filename_tf_quant = f\"Autoencoder_Final_{w}_1_{T_x}_True.tflite\"\n",
    "    tflite_model_quant_file = tflite_models_dir/filename_tf_quant\n",
    "    tflite_model_quant_file.write_bytes(tflite_model_quant)\n",
    "\n",
    "\n",
    "#     tflite_model = converter.convert()\n",
    "#     open(f'models/tflite_models//Autoencoder_Final_{w}_1_{T_x}_True.tflite' , \"wb\") .write(tflite_model)\n",
    "#     # Set interpreter...\n",
    "#     interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "# # print(interpreters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e44659d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5dd9qddo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5dd9qddo/assets\n",
      "2022-11-13 12:42:41.685295: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-11-13 12:42:41.685322: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-11-13 12:42:41.685441: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp5dd9qddo\n",
      "2022-11-13 12:42:41.687657: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-11-13 12:42:41.687672: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp5dd9qddo\n",
      "2022-11-13 12:42:41.694615: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-11-13 12:42:41.743869: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp5dd9qddo\n",
      "2022-11-13 12:42:41.759308: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 73867 microseconds.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr8h0feqn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr8h0feqn/assets\n",
      "2022-11-13 12:42:43.454813: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-11-13 12:42:43.454842: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-11-13 12:42:43.454966: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpr8h0feqn\n",
      "2022-11-13 12:42:43.457127: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-11-13 12:42:43.457143: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpr8h0feqn\n",
      "2022-11-13 12:42:43.463875: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-11-13 12:42:43.514356: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpr8h0feqn\n",
      "2022-11-13 12:42:43.527800: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 72834 microseconds.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbr4klchn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbr4klchn/assets\n",
      "2022-11-13 12:42:45.225670: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-11-13 12:42:45.225695: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-11-13 12:42:45.225813: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpbr4klchn\n",
      "2022-11-13 12:42:45.228156: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-11-13 12:42:45.228171: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpbr4klchn\n",
      "2022-11-13 12:42:45.235114: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-11-13 12:42:45.285553: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpbr4klchn\n",
      "2022-11-13 12:42:45.299093: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 73280 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"models/tflite_models_only/\")\n",
    "# tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Converting saved model to a TensorFlow Lite model.\n",
    "for w in [20, 50, 100]:\n",
    "    T_x = 1\n",
    "    filename = f'models/original_models//Autoencoder_Final_{w}_1_{T_x}_True.h5'\n",
    "    autoencoder = load_model(filename)\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)\n",
    "    # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    filename_tf = f\"Autoencoder_Final_{w}_1_{T_x}_True.tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename_tf\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "\n",
    "#     tflite_model = converter.convert()\n",
    "#     open(f'models/tflite_models//Autoencoder_Final_{w}_1_{T_x}_True.tflite' , \"wb\") .write(tflite_model)\n",
    "#     # Set interpreter...\n",
    "#     interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "# # print(interpreters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c977656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in ['Lite', 'Original']:\n",
    "    for w in [20, 50, 100]:\n",
    "    # for w in [25]:\n",
    "        # Design hyper-parameters....\n",
    "        T_xs = [1]\n",
    "        q = max(T_xs)*w\n",
    "        n = len(signals_in_cluster)\n",
    "\n",
    "        # Loading autoencoders....\n",
    "        autoencoders = {}\n",
    "        interpreters = {}\n",
    "\n",
    "        for T_x in T_xs:\n",
    "\n",
    "            if model_type == 'Original':\n",
    "                filename = f'models/lite_models//Autoencoder_Final_{w}_1_{T_x}_True'\n",
    "                # filename = f'models/original_models//Autoencoder_Final_{w}_1_{T_x}_True.h5'\n",
    "                autoencoders[T_x] = load_model(filename)\n",
    "                # print(autoencoders)\n",
    "            # else:\n",
    "            #     # Converting saved model to a TensorFlow Lite model.\n",
    "            #     filename = f'models/lite_models//Autoencoder_Final_{w}_1_{T_x}_True'\n",
    "            #     converter = tf.lite.TFLiteConverter.from_saved_model(filename)\n",
    "            #     tflite_model = converter.convert()\n",
    "            #     # Set interpreter...\n",
    "            #     interpreters[T_x] = tf.lite.Interpreter(model_content=tflite_model)\n",
    "            #     # print(interpreters)\n",
    "            else:\n",
    "                filename = f'models/tflite_models//Autoencoder_Final_{w}_1_{T_x}_True.tflite'\n",
    "                \n",
    "                if platform == 'PC':\n",
    "                    interpreters[T_x] = tf.lite.Interpreter(model_path = filename)\n",
    "                elif platform == 'RPi':\n",
    "                    interpreters[T_x] = tflite_runtime.interpreter.Interpreter(model_path = filename) \n",
    "                \n",
    "\n",
    "\n",
    "        #Setting up thresholds....\n",
    "        R_loss = np.random.rand(n)\n",
    "        R_time = (np.random.rand(n)*n).astype(int)\n",
    "        R_signal = np.random.randint(n)\n",
    "\n",
    "\n",
    "        # Initiating the dataQ\n",
    "        dataQ = pd.DataFrame(np.zeros((q, n), dtype = float), columns = signals_in_cluster)\n",
    "        dataQ.index = dataQ.index + 1\n",
    "\n",
    "        print(\"Initiating analysis.... \", w)\n",
    "        for index, data in enumerate(df_raw.values):   \n",
    "\n",
    "            begin_time = datetime.datetime.now()\n",
    "            #Reading data from the CAN bus in decoded foramt\n",
    "            can_id = int(data[2][2:])\n",
    "            signals_reported = [f'Sig_{i+1}_of_ID_{can_id}' for i in range(num_sigs_per_id[can_id])]\n",
    "            signals_missing = set(signals_in_cluster) - set(signals_reported)\n",
    "\n",
    "            # Updating dataQ    \n",
    "            new_data = [float(x) for x in data[3:3+num_sigs_per_id[can_id]]].copy()\n",
    "            dataQ.loc[2:q] = dataQ.loc[1:q-1].values.copy()\n",
    "            dataQ.loc[1, signals_reported] = new_data.copy()\n",
    "            dataQ.loc[1, signals_missing] = dataQ.loc[2, signals_missing].copy()\n",
    "            time_elapsed = datetime.datetime.now() - begin_time\n",
    "            time_needed_dataQ = float(time_elapsed.total_seconds())\n",
    "\n",
    "\n",
    "            #Creating different views and predicting reconstrcuted image\n",
    "            anomaly_S_ens = 0\n",
    "        #     prediction_time = 0\n",
    "        #     analysis_time = 0\n",
    "\n",
    "\n",
    "            for T_x in T_xs:       \n",
    "\n",
    "                prediction_time = 0\n",
    "                analysis_time = 0\n",
    "\n",
    "                # Creating different views.....\n",
    "                #starting timer\n",
    "\n",
    "                \n",
    "                dataV_org = dataQ.loc[1:(w*T_x):T_x].values.reshape(1, w, n, 1).copy()\n",
    "                dataV_org = np.array(dataV_org, dtype=np.float32)\n",
    "                \n",
    "                if model_type != 'Original':\n",
    "                    dataV_org = np.array(dataV_org, dtype=np.float32)\n",
    "\n",
    "                begin_time = datetime.datetime.now()\n",
    "\n",
    "                # Predict.....\n",
    "                if model_type == 'Original':\n",
    "                    # print(\"autoencoders\", autoencoders)\n",
    "                    dataV_recon = autoencoders[T_x].predict(dataV_org)\n",
    "                \n",
    "                else:\n",
    "                    # print(\"interpreters\", interpreters)\n",
    "                    interpreter = interpreters[T_x]\n",
    "                    interpreter.allocate_tensors() \n",
    "                    #get input and output tensors\n",
    "                    input_details = interpreter.get_input_details()\n",
    "                    output_details = interpreter.get_output_details()\n",
    "\n",
    "                    #set the tensor to point to the input data to be inferred\n",
    "                    input_index = input_details[0][\"index\"]\n",
    "                    interpreter.set_tensor(input_index, dataV_org)\n",
    "                    #Run the inference\n",
    "                    interpreter.invoke()\n",
    "                    output_details = interpreter.get_output_details()\n",
    "                    # Output\n",
    "                    dataV_recon = interpreter.get_tensor(output_details[0]['index'])\n",
    "                    \n",
    "\n",
    "                        \n",
    "\n",
    "                #stopping timer\n",
    "                time_elapsed = datetime.datetime.now() - begin_time\n",
    "                prediction_time += float(time_elapsed.total_seconds())\n",
    "                \n",
    "    #             dataV_recon = dataV_recon[0,:,:,0].copy()\n",
    "\n",
    "                #starting timer\n",
    "                begin_time = datetime.datetime.now()\n",
    "\n",
    "                dataV_loss = abs(dataV_org - dataV_recon)[0,:,:,0].copy()\n",
    "                #finding anomaly scores for individual models...\n",
    "                anomaly_B = (dataV_loss > R_loss).astype(int)\n",
    "                anomaly_C = np.sum(anomaly_B,0)\n",
    "                anomaly_S = np.sum(anomaly_C > R_time)\n",
    "                anomaly_S_ens += anomaly_S\n",
    "\n",
    "                #stopping timer\n",
    "                time_elapsed = datetime.datetime.now() - begin_time\n",
    "                analysis_time  += float(time_elapsed.total_seconds())\n",
    "\n",
    "                time_data.append([w, T_x, time_needed_dataQ, prediction_time, analysis_time, model_type])\n",
    "\n",
    "\n",
    "\n",
    "        #         if anomaly_S > R_signal:\n",
    "        #             predictions[T_x].append(1)\n",
    "        #         else:\n",
    "        #             predictions[T_x].append(0)    \n",
    "\n",
    "\n",
    "            # Checking the final ensemble score..\n",
    "        #     if anomaly_S_ens > R_signal_ens:\n",
    "        #         predictions['Ens'].append(1)\n",
    "        #     else:\n",
    "        #         predictions['Ens'].append(0)   \n",
    "\n",
    "        #     time_data.append([w, T_x, time_needed_dataQ, prediction_time, analysis_time])\n",
    "\n",
    "            if index == 100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee4a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(time_data, columns = ['w', 'Tx', 'Data Queue', 'Prediction', 'Analysis', 'Model Type'])\n",
    "time_df[['Data Queue', 'Prediction', 'Analysis']]*= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf39d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.to_csv('framework_performance.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sns.barplot(data = time_df, x = 'w', y = 'Prediction')\n",
    "# sns.barplot(data = time_df, x = 'w', y = 'Data Queue')\n",
    "# sns.barplot(data = time_df, x = 'w', y = 'Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = time_df, hue = 'w', y = 'Data Queue', x = 'Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = time_df, hue = 'w', y = 'Prediction', x = 'Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = time_df[time_df['Model Type'] == 'Original'], hue = 'w', y = 'Prediction', x = 'Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = time_df[time_df['Model Type'] == 'Lite'], hue = 'w', y = 'Prediction', x = 'Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = time_df, hue = 'w', y = 'Analysis', x = 'Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw['Time'] = df_raw['Time'].astype(float)\n",
    "\n",
    "# df_raw['Time'][0:100].iloc[0] - df_raw['Time'][0:100].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw['Time'][0:100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06fe43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "76b18d0804b1d18cc4a8723b732596a057f641d6427a46ef33e32599b5d9a6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
